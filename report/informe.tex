\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{booktabs}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{upquote}

% Configuración de página
\geometry{margin=2.5cm}
\setlength{\headheight}{14.49998pt}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{Sistema de Scrapping Web Distribuido}
\fancyfoot[C]{\thepage}

% Configuración de código
\lstset{
    backgroundcolor=\color{gray!10},
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true,
    captionpos=b,
    inputencoding=utf8,
    extendedchars=true,
    literate=
        {á}{{\'{a}}}1 {é}{{\'{e}}}1 {í}{{\'{i}}}1 {ó}{{\'{o}}}1 {ú}{{\'{u}}}1
        {Á}{{\'{A}}}1 {É}{{\'{E}}}1 {Í}{{\'{I}}}1 {Ó}{{\'{O}}}1 {Ú}{{\'{U}}}1
        {ñ}{{\~{n}}}1 {Ñ}{{\~{N}}}1 {ü}{{\"u}}1 {Ü}{{\"U}}1
}

% Configuración de títulos
\titleformat{\section}{\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\large\bfseries}{\thesubsection}{1em}{}

\begin{document}

% Portada
\begin{titlepage}
    \centering
    \vspace*{2cm}
    
    {\huge\bfseries Sistema de Scrapping Web Distribuido}
    
    \vspace{1cm}
    {\Large Proyecto de Sistemas Distribuidos}
    
    \vspace{1.5cm}
    {\large
    Implementación de un sistema distribuido para extracción \\
    automatizada de contenido web utilizando Docker Swarm
    }
    
    \vspace{2cm}
    {\large
    Estudiantes: David S\'anchez Iglesias y Manuel Alejandro Gamboa Hern\'andez\\
    Asignatura: Sistemas Distribuidos
    }
    
    \vfill
    {\large Universidad de La Habana}
    
    \vspace{0.5cm}
    {\large \today}
    
\end{titlepage}

% Tabla de contenidos
\tableofcontents
\newpage

% Introducción
\section{Introducción}

\subsection{Contexto del Proyecto}

Los sistemas distribuidos han revolucionado la manera en que procesamos y analizamos grandes volúmenes de información en la era digital. En particular, el web scrapping o extracción automatizada de contenido web se ha convertido en una técnica fundamental para la recopilación de datos a gran escala, utilizada en campos que van desde el análisis de mercado hasta la investigación académica.

El presente proyecto implementa un \textbf{Sistema de Scrapping Web Distribuido} que aprovecha las ventajas de la computación distribuida para realizar extracción de contenido web de manera eficiente, escalable y tolerante a fallos. El sistema está diseñado bajo los principios fundamentales de los sistemas distribuidos: distribución de carga, escalabilidad horizontal, tolerancia a fallos y comunicación eficiente entre componentes.

\subsection{Problemática Abordada}

El scrapping web tradicional, ejecutado en un solo servidor, presenta limitaciones significativas:

\begin{itemize}
    \item \textbf{Limitaciones de rendimiento}: Un \'unico nodo solo puede procesar un número limitado de páginas web simultáneamente
    \item \textbf{Falta de escalabilidad}: No es posible aumentar la capacidad de procesamiento dinámicamente
    \item \textbf{Punto único de falla}: El sistema completo se ve afectado si el servidor único falla
    \item \textbf{Ineficiencia en recursos}: No aprovecha completamente los recursos disponibles en múltiples máquinas
\end{itemize}

\subsection{Objetivos del Sistema}

\subsubsection{Objetivo General}
Desarrollar un sistema distribuido que permita realizar scrapping web de manera eficiente, escalable y confiable, utilizando múltiples nodos de procesamiento coordinados a través de una arquitectura cliente-servidor distribuida.

\subsubsection{Objetivos Específicos}
\begin{enumerate}
    \item \textbf{Especialización de nodos}: Implementar tres tipos de nodos especializados (Base de Datos, Enrutador, Scrapper) con responsabilidades claramente definidas
    \item \textbf{Pipeline de datos eficiente}: Desarrollar un flujo de datos optimizado desde la entrada de URLs hasta la persistencia de resultados
    \item \textbf{Workers puros escalables}: Diseñar nodos scrapper stateless que permitan escalabilidad horizontal sin complejidad adicional
    \item \textbf{Coordinación inteligente}: Implementar nodos enrutadores que gestionen eficientemente la distribución de tareas y recolección de resultados
    \item \textbf{Persistencia confiable}: Desarrollar nodos de base de datos que garanticen el almacenamiento seguro de información scrapeada
    \item \textbf{Sistema de liderazgo distribuido}: Implementar algoritmo bully para elección automática de líderes en cada grupo de nodos
    \item \textbf{Tolerancia a fallos multi-nivel}: Desarrollar mecanismos de recuperación que incluyan IP caché para fallos de DNS y elección automática de líderes
    \item \textbf{Replicación automática}: Garantizar que la información se replique automáticamente entre nodos del mismo grupo
    \item \textbf{Filtrado de calidad}: Asegurar que solo datos exitosamente scrapeados lleguen a la capa de persistencia
\end{enumerate}

\subsection{Arquitectura General del Sistema}

El sistema implementa una arquitectura distribuida de tres capas con especialización de roles. La arquitectura está compuesta por tres tipos de nodos principales que operan de manera coordinada:

\subsubsection{Nodos Base de Datos}
\textbf{Función}: Almacenamiento y persistencia de información
\begin{itemize}
    \item Reciben datos scrapeados procesados desde los nodos enrutadores
    \item Gestionan el almacenamiento persistente de la información extraída
    \item Proveen servicios de consulta y recuperación de datos históricos
    \item Implementan mecanismos de redundancia y respaldo de información
\end{itemize}

\subsubsection{Nodos Enrutador/Coordinador}
\textbf{Función}: Transmisión de información y manejo de peticiones
\begin{itemize}
    \item Actúan como intermediarios de comunicación entre diferentes tipos de nodos
    \item Transmiten información entre los líderes de los diferentes grupos
    \item Manejan las peticiones de los clientes externos
    \item Facilitan la comunicación inter-grupos sin distribuir tareas directamente
\end{itemize}

\subsubsection{Nodos Scrapper (Workers)}
\textbf{Función}: Procesamiento puro de extracción web
\begin{itemize}
    \item Workers especializados en extracción de contenido web
    \item Reciben URLs específicas para procesar
    \item Ejecutan el proceso de scrapping de manera autónoma
    \item Retornan resultados estructurados al nodo enrutador
\end{itemize}

\subsubsection{Infraestructura de Soporte}
\begin{itemize}
    \item \textbf{Red Overlay}: Infraestructura de comunicación basada en Docker Swarm
    \item \textbf{Sistema de Descubrimiento}: Mecanismo automático para detección y registro de servicios
    \item \textbf{Gateway API}: Interfaz REST para interacción externa y monitoreo del sistema
\end{itemize}

\section{Sistema de Balanceo de Carga y Liderazgo Distribuido}

\subsection{Arquitectura Común de Comunicación}

Todos los tipos de nodos del sistema (scrapper, enrutador y base de datos) comparten una arquitectura común de comunicación que implementa cuatro actividades fundamentales:

\subsubsection{Sistema de Escucha}
\begin{itemize}
    \item Apertura de puerto de escucha mediante \texttt{socket.bind~()}
    \item Hilo dedicado para \texttt{socket.accept~()} que registra nuevos sockets
    \item Creación de hilos especializados para procesar mensajes entrantes
\end{itemize}

\subsubsection{Conexión con Nodos Semejantes}
\begin{itemize}
    \item Método \texttt{buscar\_semejantes~()} para conectarse con nodos del mismo rol
    \item Uso de \texttt{--hostname} y \texttt{--network-alias} de Docker
    \item \texttt{socket.getaddrinfo~(network\_alias)} para obtener IPs de servicios
    \item Establecimiento de conexiones peer-to-peer mediante \texttt{socket.create\_connection~()}
    \item Ejecución periódica para descubrir nuevos servicios dinámicamente
\end{itemize}

\subsubsection{Sistema de Envío de Mensajes}
\begin{itemize}
    \item Cola de mensajes con tuplas (mensaje, socket\_destino)
    \item Proceso \texttt{send\_worker~()} que consume la cola con timeout
    \item Protocolo de envío: longitud del mensaje + mensaje completo
    \item Método thread-safe para inserción en la cola
\end{itemize}

\subsubsection{Funcionalidades de Mantenimiento}
\begin{itemize}
    \item \texttt{send\_heartbeat~()}: Confirmación periódica de conectividad
    \item Monitoreo del estado de conexiones peer-to-peer
    \item Detección de fallos y reconexión automática
    \item Gestión del ciclo de vida de hilos de comunicación
\end{itemize}

\subsection{Algoritmo Bully para Elección de Líderes}

\subsubsection{Principio del Algoritmo}
El sistema implementa el algoritmo bully para la elección de líderes en cada grupo de nodos:

\begin{itemize}
    \item \textbf{Criterio de selección}: El nodo con la IP más alta se convierte en líder
    \item \textbf{Proceso determinístico}: No requiere votación ni intervención manual
    \item \textbf{Automático}: La conexión peer-to-peer facilita la comparación de IPs
    \item \textbf{Jerárquico}: Basado en un orden natural (direcciones IP)
\end{itemize}

\subsubsection{Proceso de Elección}
\begin{enumerate}
    \item Cada nodo obtiene las IPs de todos los nodos del mismo tipo
    \item Se establece comunicación peer-to-peer con los nodos descubiertos
    \item Comparación automática de IPs durante el proceso de conexión
    \item El nodo con mayor IP asume automáticamente el rol de líder
    \item Notificación implícita del liderazgo a través de las conexiones
\end{enumerate}

\subsubsection{Responsabilidades Diferenciadas por Tipo de Nodo}
\textbf{Líderes de Base de Datos y Enrutadores}:
\begin{itemize}
    \item Replican toda información recibida a sus subordinados
    \item Mantienen sincronización completa de datos en el grupo
    \item Coordinación inter-grupos con otros líderes
    \item Gestión de replicación y consistencia de información
\end{itemize}

\textbf{Líder de Scrappers}:
\begin{itemize}
    \item \textbf{No replica información} --- mantiene función pura de procesamiento
    \item Gestiona distribución de carga entre scrappers subordinados
    \item Reporta estado del grupo sin distribuir datos de scrapping
\end{itemize}

\subsection{Recuperación ante Fallos de Liderazgo}

\subsubsection{Detección de Fallos}
\begin{itemize}
    \item Monitoreo mediante heartbeat entre nodos
    \item Timeout de comunicación para detectar nodos caídos
    \item Verificación periódica del estado de conexiones
\end{itemize}

\subsubsection{Reelección Automática}
Cuando el líder actual falla:
\begin{enumerate}
    \item Los nodos detectan la pérdida de comunicación con el líder
    \item Reinicio del proceso de elección bully
    \item El nodo con la segunda IP más alta asume el liderazgo
    \item Reestablecimiento de conexiones inter-grupos
    \item Continuidad operativa sin intervención manual
\end{enumerate}

\subsubsection{Garantías del Sistema}
\begin{itemize}
    \item \textbf{Disponibilidad}: Reelección automática sin interrupción de servicio
    \item \textbf{Consistencia}: Un único líder por grupo en todo momento
    \item \textbf{Determinismo}: Resultado predecible basado en IPs
    \item \textbf{Escalabilidad}: Incorporación transparente de nuevos nodos
\end{itemize}

\section{Componente Scrapper: Nodo Worker Especializado}

\subsection{Descripción General}

El componente \textbf{Scrapper} constituye la capa de procesamiento del sistema distribuido, organizado jerárquicamente con un \textbf{líder que coordina y distribuye tareas} entre los \textbf{nodos subordinados}. La función del líder es recibir URLs de los enrutadores y distribuirlas entre sus workers subordinados, adem\'as de, como sus subordinados, ejecutar el scrapping web y retornar resultados estructurados.

\subsubsection{Principios de Diseño del Worker con Coordinación}
\begin{itemize}
    \item \textbf{Especialización funcional}: Se enfoca únicamente en la extracción de contenido web
    \item \textbf{Worker puro}: No replica información, solo procesa URLs (URL → Resultado)
    \item \textbf{Participación en liderazgo}: Vota por líder y acepta coordinación del grupo
    \item \textbf{Stateless para datos}: No mantiene estado de scrapping entre tareas
    \item \textbf{Escalabilidad horizontal}: Permite instanciación múltiple con coordinación automática
\end{itemize}

Cada instancia de scrapper participa en el sistema de liderazgo distribuido de su grupo. El líder scrapper actúa como coordinador con otros grupos, y transmite las direcciones de los otros líderes con los que interactúa a sus subordinados en caso de cambios en la topología o fallos detectados.

\subsection{Arquitectura del Scrapper}

\subsubsection{Diseño de Clases}
El scrapper está implementado a través de la clase \texttt{ScrapperNode}, que encapsula toda la funcionalidad necesaria para:

\begin{itemize}
    \item Autodescubrimiento de servicios coordinadores
    \item Gestión de conexiones de red persistentes  
    \item Procesamiento asíncrono de tareas de scrapping
    \item Comunicación bidireccional con el coordinador
    \item Manejo de estados y recuperación ante fallos
\end{itemize}

\subsubsection{Patrones de Diseño Implementados}

\textbf{1. Patrón Observer}: Para el manejo de eventos de red y cambios de estado

\textbf{2. Patrón Producer-Consumer}: Para la gestión de colas de mensajes entre hilos

\textbf{3. Patrón State Machine}: Para el manejo de estados del scrapper (disponible, ocupado, desconectado)

\subsection{Funcionalidades Principales}

\subsubsection{Gestión de Conexiones}

El sistema implementa un modelo de conexiones persistentes con gestión de hilos especializada, utilizando protocolos binarios optimizados y colas de mensajes thread-safe.

\textbf{Características de la gestión de conexiones}:
\begin{itemize}
    \item \textbf{Protocolo binario optimizado}: Uso de longitud prefijada para eficiencia
    \item \textbf{Cola de mensajes thread-safe}: Comunicación asíncrona entre hilos
    \item \textbf{Reconexión automática}: Detección y recuperación de desconexiones
    \item \textbf{Timeouts configurables}: Prevención de bloqueos indefinidos
\end{itemize}

\subsubsection{Procesamiento de Tareas de Scrapping}

El núcleo del procesamiento de tareas integra el módulo especializado \texttt{scrapper.py}, que implementa el scrapping web utilizando librerías como \texttt{requests} y \texttt{BeautifulSoup}.

\subsubsection{Sistema de Heartbeat y Monitoreo}

Implementación de un sistema de latidos para mantener la conectividad mediante señales periódicas cada 60 segundos que incluyen identificación del cliente y timestamp para monitoreo de conectividad.

\subsection{Ventajas del Diseño Distribuido del Scrapper}

\subsubsection{Escalabilidad Horizontal}
\begin{itemize}
    \item Capacidad de agregar nodos scrapper dinámicamente
    \item Distribución automática de carga entre nodos disponibles
    \item Adaptación automática a variaciones en la demanda
\end{itemize}

\subsubsection{Tolerancia a Fallos}
\begin{itemize}
    \item Detección automática de fallos de nodo
    \item Redistribución de tareas ante fallos
    \item Reconexión automática de nodos recuperados
\end{itemize}

\subsubsection{Eficiencia de Recursos}
\begin{itemize}
    \item Procesamiento paralelo de múltiples URLs
    \item Utilización optimizada de recursos de red
    \item Balanceo automático de carga de trabajo
\end{itemize}

\section{Componente Enrutador: Nodo de Comunicación y Gestión de Peticiones}

\subsection{Descripción General}

Los nodos enrutadores constituyen la capa de comunicación del sistema distribuido, actuando como intermediarios que gestionan las peticiones de los clientes y facilitan la comunicación entre los diferentes grupos de nodos. Su función principal es recibir consultas sobre información almacenada y URLs a procesar, transmitiendo esta información a los líderes correspondientes de cada grupo.

\subsubsection{Funciones Principales del Enrutador}
\begin{itemize}
    \item \textbf{Gestión de peticiones de clientes}: Reciben consultas sobre datos scrapeados almacenados
    \item \textbf{Recepción de URLs}: Punto de entrada para nuevas tareas de scrapping
    \item \textbf{Transmisión inter-grupos}: Facilitan comunicación entre líderes de diferentes grupos
    \item \textbf{Coordinación de respuestas}: Recolectan y organizan respuestas para los clientes
    \item \textbf{Indexaci\'on de respuestas}: Mantienen un índice de URLs procesadas y sus ubicaciones en base de datos, concretamente las IPs de los nodos BD donde se almacenan los datos scrapeados
\end{itemize}

\subsection{Arquitectura del Enrutador}

El nodo enrutador utiliza la arquitectura común de comunicación descrita en la sección de balanceo de carga, especializándose en:
\begin{itemize}
    \item Gestión de peticiones de clientes externos
    \item Coordinación entre líderes de diferentes grupos
    \item Distribución de URLs de scrapping a procesar
    \item Recolección y organización de respuestas
\end{itemize}

\subsubsection{Responsabilidades del Líder Enrutador}
\begin{itemize}
    \item Establecimiento de conexión socket con líder de BD
    \item Búsqueda activa de servicios de otros roles
    \item Envío de URLs a procesar al líder del grupo scrapper
    \item Proporciona IP del líder BD para almacenamiento directo
    \item Coordina el flujo de información entre grupos
\end{itemize}

\section{Componente Base de Datos: Nodo de Almacenamiento y Persistencia}

\subsection{Descripción General}

Los nodos de base de datos constituyen la capa de persistencia del sistema, encargados de almacenar la información extraída por los scrappers y gestionar la replicación de datos para garantizar disponibilidad y consistencia. Implementan un sistema de liderazgo distribuido con replicación aleatoria y gestión de logs para recuperación ante fallos.

\subsubsection{Funciones Principales}
\begin{itemize}
    \item \textbf{Almacenamiento de datos}: Persistencia de información scrapeada
    \item \textbf{Replicación distribuida}: Almacenamiento en múltiples nodos (típicamente 3 réplicas)
    \item \textbf{Gestión de logs}: Registro de operaciones para recuperación
    \item \textbf{Coordinación de acceso}: Facilitación de consultas de datos almacenados
\end{itemize}

\subsection{Arquitectura de Base de Datos}

Los nodos BD utilizan la arquitectura común de comunicación, especializándose en:

\subsubsection{Especialización para Almacenamiento}
\begin{itemize}
    \item Recepción directa de datos desde nodos scrapper
    \item Procesamiento de información estructurada
    \item Gestión de metadatos y logs de operaciones
    \item Coordinación de replicación entre nodos BD
\end{itemize}

\subsubsection{Responsabilidades del Líder BD}
\begin{itemize}
    \item \textbf{Gestión de replicación}: Selección aleatoria de 3 nodos BD para almacenamiento
    \item \textbf{Coordinación con enrutador}: Envío de tuplas (URL, IPs) con ubicaciones de datos
    \item \textbf{Gestión de logs}: Almacenamiento de logs de todos los nodos no-líderes
    \item \textbf{Recuperación ante fallos}: Reconstrucción de nodos caídos mediante logs
\end{itemize}

\subsection{Estrategia de Replicación y Recuperación}

\subsubsection{Replicación Aleatoria}
\textbf{Proceso de Almacenamiento}:
\begin{enumerate}
    \item Recepción de información desde scrapper
    \item Selección aleatoria de 3 nodos BD para replicación
    \item Distribución de datos a nodos seleccionados
    \item Envío de tupla (URL, IPs\_almacenamiento) al líder enrutador
    \item Registro de operación en logs para trazabilidad
\end{enumerate}

\subsubsection{Recuperación ante Fallos}
\textbf{Caída de Nodo No-Líder}:
\begin{enumerate}
    \item Detección de fallo mediante ausencia de heartbeat
    \item Incorporación de nuevo nodo BD al grupo
    \item Reconstrucción usando logs almacenados por el líder
    \item Restauración de réplicas y mantenimiento de factor de replicación
\end{enumerate}

\textbf{Caída del Líder BD}:
\begin{enumerate}
    \item Elección automática de nuevo líder (algoritmo bully)
    \item Envío de logs locales al nuevo líder por parte de todos los nodos
    \item Consolidación de información de logs distribuidos
    \item Restablecimiento de función de liderazgo y coordinación
    \item Continuidad de replicación usando logs históricos
\end{enumerate}

\section{Flujo de Datos y Comunicación Inter-Nodos}

\subsection{Pipeline de Procesamiento Distribuido}

El sistema implementa un pipeline de datos distribuido que sigue el siguiente flujo:

\begin{enumerate}
    \item \textbf{Entrada de URLs}: Las URLs a procesar ingresan al sistema a través del Gateway API
    \item \textbf{Recepción}: Los nodos enrutadores reciben las peticiones y las transmiten al líder correspondiente
    \item \textbf{Distribución de Tareas}: Los \textbf{líderes de cada grupo} distribuyen las tareas entre sus nodos subordinados
    \item \textbf{Procesamiento}: Los nodos scrapper ejecutan el scrapping de manera independiente bajo coordinación de su líder
    \item \textbf{Recolección}: Los líderes recolectan resultados y coordinan con otros líderes
    \item \textbf{Transmisión}: Los enrutadores transmiten la información entre líderes de diferentes grupos
    \item \textbf{Persistencia}: Los datos procesados llegan al líder de BD para distribución y almacenamiento
\end{enumerate}

\subsection{Patrones de Comunicación}

\subsubsection{Enrutador → Líder Scrapper}
\begin{itemize}
    \item \textbf{Tipo}: Transmisión de información entre líderes
    \item \textbf{Contenido}: URLs recibidas de clientes
    \item \textbf{Protocolo}: Comunicación líder a líder
\end{itemize}

\subsubsection{Líder Scrapper → Subordinados Scrapper}
\begin{itemize}
    \item \textbf{Tipo}: Distribución real de tareas dentro del grupo
    \item \textbf{Contenido}: URLs específicas asignadas por el líder
    \item \textbf{Responsable}: El líder scrapper gestiona la distribución
\end{itemize}

\subsubsection{Scrapper → Líder Base de Datos}
\begin{itemize}
    \item \textbf{Tipo}: Envío directo de resultados
    \item \textbf{Contenido}: Datos extraídos procesados
    \item \textbf{Optimización}: Evita doble salto de información
\end{itemize}

\subsection{Tolerancia a Fallos y Mecanismos de Recuperación}

\subsubsection{Estrategias de Tolerancia a Fallos por Capas}
\textbf{Nivel de Pipeline}:
\begin{itemize}
    \item \textbf{Timeout de scrapping}: Los workers tienen límites de tiempo por tarea
    \item \textbf{Reasignación automática}: Las tareas fallidas se reasignan a otros workers
    \item \textbf{Filtrado de resultados}: Solo los scrappings exitosos continúan en el pipeline
    \item \textbf{Heartbeat continuo}: Detección temprana de nodos no responsivos
\end{itemize}

\subsubsection{IP caché para Recuperación de DNS}
Como medida adicional de tolerancia a fallos, cada nodo implementa un \textbf{sistema de caché de IPs} que proporciona resiliencia ante fallos del servicio DNS de Docker:

\textbf{Características del IP caché}:
\begin{itemize}
    \item \textbf{Registro automático}: Cada nodo mantiene un registro de IPs de nodos con los que ha interactuado previamente
    \item \textbf{Recuperación ante fallos de DNS}: Si el servicio DNS de Docker falla, los nodos pueden continuar comunicándose usando las IPs cacheadas
    \item \textbf{Persistencia local}: El caché se mantiene localmente en cada nodo para acceso rápido
    \item \textbf{Actualización dinámica}: Las IPs se actualizan automáticamente durante las comunicaciones exitosas
\end{itemize}

\textbf{Ventajas del IP caché}:
\begin{itemize}
    \item Continuidad operativa ante fallos de infraestructura
    \item Reducción de dependencias externas críticas
    \item Mejora en los tiempos de recuperación del sistema
    \item Mantenimiento de conectividad entre nodos conocidos
\end{itemize}



\section{Consistencia y Replicación de Datos}

\subsection{Estrategias de Distribución de Datos}

\subsubsection{Modelo de Replicación por Grupos}
El sistema implementa diferentes estrategias de replicación según el tipo de nodo:

\begin{itemize}
    \item \textbf{Grupos de Base de Datos}: Replicación completa (Full Replication)
    \begin{itemize}
        \item Cada nodo BD mantiene copia completa de todos los datos
        \item Sincronización inmediata tras cada escritura
        \item Consistencia fuerte dentro del grupo
    \end{itemize}
    \item \textbf{Grupos de Coordinadores}: Replicación de estado
    \begin{itemize}
        \item Estado del sistema y decisiones replicadas
        \item Información de nodos activos sincronizada
        \item Configuraciones y políticas distribuidas
    \end{itemize}
    \item \textbf{Grupos de Scrappers}: Sin replicación de datos
    \begin{itemize}
        \item Cada scrapper mantiene solo su estado local
        \item Resultados enviados directamente a coordinadores
        \item Funcionalidad pura sin persistencia
    \end{itemize}
\end{itemize}

\subsubsection{Cantidad y Distribución de Réplicas}
\textbf{Política de Replicación}:
\begin{itemize}
    \item \textbf{Factor de Replicación}: Mínimo 3 réplicas por dato crítico
    \item \textbf{Distribución Geográfica}: Réplicas en diferentes nodos físicos
    \item \textbf{Algoritmo de Distribución}: \textbf{Selección aleatoria} de nodos destino
    \item \textbf{Simplicidad}: Sin balanceado de carga complejo por ahora
\end{itemize}

El sistema implementa replicación mediante selección aleatoria de nodos disponibles, manteniendo un mínimo de 3 réplicas por dato crítico cuando sea posible.

\subsection{Confiabilidad de Réplicas tras Actualizaciones}

\subsubsection{Protocolo de Consistencia}
\textbf{Garantías de Consistencia}:
\begin{itemize}
    \item \textbf{Consistencia Eventual}: Para datos no críticos
    \item \textbf{Consistencia Fuerte}: Para datos del sistema y configuraciones
    \item \textbf{Ordenamiento de Escrituras}: Timestamps para resolver conflictos
\end{itemize}

\textbf{Mecanismos de Verificación}:
\begin{itemize}
    \item \textbf{Checksums}: Verificación de integridad de datos replicados
    \item \textbf{Heartbeat con Estado}: Inclusión de información de consistencia
    \item \textbf{Reconciliación Periódica}: Comparación y corrección de diferencias
\end{itemize}

\subsubsection{Recuperación ante Inconsistencias}
\begin{enumerate}
    \item \textbf{Detección}: Identificación de réplicas inconsistentes
    \item \textbf{Votación}: Determinación de versión correcta mediante consenso
    \item \textbf{Corrección}: Actualización de réplicas incorrectas
    \item \textbf{Verificación}: Confirmación de consistencia restaurada
\end{enumerate}



\section{Conclusiones}

La arquitectura de tres capas con sistema de liderazgo distribuido proporciona una solución robusta y escalable para el procesamiento distribuido de web scrapping. La combinación del algoritmo bully para elección de líderes, la replicación automática de información y el sistema de IP caché para tolerancia a fallos de DNS, resulta en un sistema altamente resiliente.

El diseño de microservicios puros con threading multi-propósito optimiza el uso de recursos mientras mantiene separación clara de responsabilidades. La distribución en redes Docker overlay facilita el escalado horizontal y la gestión de servicios distribuidos geográficamente.

El sistema de replicación diferenciado por grupos --- con replicación completa para datos críticos y especialización sin replicación para workers --- proporciona un balance óptimo entre consistencia, rendimiento y escalabilidad. Los mecanismos de consistencia eventual y fuerte, según el tipo de datos, garantizan la integridad del sistema.

El diseño jerárquico con líderes en todos los grupos optimiza la comunicación inter-grupos mientras mantiene redundancia y capacidad de recuperación automática ante fallos. Los nodos scrapper, aunque participan en el sistema de liderazgo distribuido, mantienen su especialización como workers puros, garantizando simplicidad operativa y máxima escalabilidad horizontal con coordinación inteligente.

Las características implementadas, como el autodescubrimiento de servicios mediante DNS de Docker, la gestión de conexiones persistentes con threading especializado, el sistema de heartbeat distribuido y las estrategias de replicación adaptativas, demuestran la aplicación integral de conceptos fundamentales de sistemas distribuidos en un contexto real de procesamiento de datos web.

\end{document}