# ğŸ•·ï¸ Sistema de Scraping Distribuido

Sistema distribuido para scraping web con arquitectura jerÃ¡rquica de nodos Router, Scrapper y Base de Datos.

## ğŸ¯ CaracterÃ­sticas

- **Arquitectura distribuida** con nodos Router, Scrapper y BD
- **ElecciÃ³n de lÃ­deres** automÃ¡tica para alta disponibilidad
- **Balanceo de carga** Round-Robin entre nodos Scrapper
- **Interfaz web** moderna con Streamlit
- **Cliente CLI** interactivo
- **Docker Swarm** para despliegue multi-nodo
- **Heartbeat monitoring** para detecciÃ³n de fallos

## ğŸš€ Inicio RÃ¡pido

### ConstrucciÃ³n

```bash
# Crear red Docker
make network

# Construir todas las imÃ¡genes
make build-all
```

### EjecuciÃ³n

```bash
# OpciÃ³n 1: Sistema completo con interfaz web
make run-all

# La interfaz estarÃ¡ en http://localhost:8501
```

```bash
# OpciÃ³n 2: Solo componentes especÃ­ficos
make run-scrappers  # 4 nodos scrapper
make run-routers    # 4 nodos router  
make run-streamlit  # Interfaz web
```

### Uso de la Interfaz Web

1. Abre http://localhost:8501 en tu navegador
2. Haz clic en **"Conectar"** en la barra lateral
3. Ingresa una URL en el formulario (ej: https://www.python.org)
4. Haz clic en **"Scrapear"**
5. Ve los resultados en tiempo real

### Limpieza

```bash
# Limpiar todos los contenedores
make clean-all

# Limpiar red
make network-clean
```

## ğŸ“‹ Comandos Disponibles

Ver todos los comandos:
```bash
make help
```

### ConstrucciÃ³n
- `make build-scrapper` - Construir imagen de Scrapper
- `make build-router` - Construir imagen de Router
- `make build-streamlit` - Construir interfaz Streamlit
- `make build-all` - Construir todo

### EjecuciÃ³n
- `make run-scrappers` - Ejecutar 4 nodos Scrapper
- `make run-routers` - Ejecutar 4 nodos Router
- `make run-streamlit` - Ejecutar interfaz web
- `make run-all` - Ejecutar sistema completo

### Logs
- `make logs-scrapper` - Ver logs del primer Scrapper
- `make logs-router` - Ver logs del primer Router
- `make logs-streamlit` - Ver logs de la interfaz

### Limpieza
- `make clean-scrappers` - Limpiar nodos Scrapper
- `make clean-routers` - Limpiar nodos Router
- `make clean-streamlit` - Limpiar interfaz
- `make clean-all` - Limpiar todo

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit UI   â”‚ â† Interfaz web (puerto 8501)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Router Jefe    â”‚ â† Coordina tareas
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scrapper Jefe   â”‚ â† Asigna tareas
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scrapper Worker â”‚ â† Ejecuta scraping
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

1. **Router Nodes**: Reciben peticiones de clientes, coordinan con Scrappers y BD
2. **Scrapper Nodes**: Ejecutan tareas de scraping web
3. **BD Nodes**: Almacenan resultados (en desarrollo)
4. **Streamlit UI**: Interfaz web para usuarios
5. **Cliente CLI**: Cliente interactivo de lÃ­nea de comandos

## ğŸ¨ Interfaz Streamlit

### CaracterÃ­sticas

- âœ… **Dashboard en tiempo real** - MÃ©tricas de tareas procesadas
- ğŸ•·ï¸ **Formulario de scraping** - EnvÃ­o simple de URLs
- ğŸ“Š **VisualizaciÃ³n de resultados** - Lista con filtros
- ğŸ”Œ **GestiÃ³n de conexiÃ³n** - Conectar/desconectar del router
- â³ **Tareas pendientes** - Ver estado en tiempo real
- ğŸ“‹ **Historial completo** - Todos los resultados con detalles

### Capturas

La interfaz muestra:
- Total de tareas procesadas
- Tareas exitosas vs fallidas  
- Tareas pendientes
- Formulario para enviar URLs
- Resultados con tÃ­tulo, tamaÃ±o y timestamp

## ğŸ³ Docker

### ImÃ¡genes

- `scrapper_node` - Nodo Scrapper
- `router_node` - Nodo Router
- `streamlit-app` - Interfaz web
- `interactive_client` - Cliente CLI

### Red

Todos los contenedores se ejecutan en la red `scrapper-network` (overlay).

## ğŸ”§ Desarrollo

### Requisitos

- Docker
- Make
- Python 3.11+ (para desarrollo local)

### Estructura del Proyecto

```
.
â”œâ”€â”€ base_node/          # CÃ³digo base compartido
â”œâ”€â”€ router/             # Nodo Router
â”œâ”€â”€ scrapper/           # Nodo Scrapper
â”œâ”€â”€ database/           # Nodo BD (en desarrollo)
â”œâ”€â”€ client/             # Cliente CLI
â”œâ”€â”€ streamlit_app/      # Interfaz Streamlit
â”œâ”€â”€ common/             # Utilidades compartidas
â”œâ”€â”€ Makefile            # Comandos de automatizaciÃ³n
â””â”€â”€ README.md           # Este archivo
```

## ğŸ“ Notas

- Los nodos eligen automÃ¡ticamente un lÃ­der usando Bully Algorithm
- El sistema soporta caÃ­das de nodos y reelecciÃ³n de lÃ­deres
- La interfaz Streamlit se actualiza automÃ¡ticamente cada segundo
- Los resultados se muestran en orden cronolÃ³gico inverso

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto es parte de un proyecto acadÃ©mico de Sistemas Distribuidos.

