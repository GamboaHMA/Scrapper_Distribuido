# Cliente Web de Scrapping

Cliente web simple para el sistema distribuido de scrapping. **NO usa frameworks como Flask, Streamlit o FastAPI**, solo Python est√°ndar con `http.server` y HTML/CSS/JavaScript puro.

## Caracter√≠sticas

- ‚úÖ **Sin frameworks externos**: Solo usa `http.server` de Python est√°ndar
- üîÑ **Reconexi√≥n autom√°tica**: Se reconecta autom√°ticamente si el router se cae
- üé® **Interfaz moderna**: HTML/CSS/JavaScript puro con dise√±o responsive
- üìä **Resultados en tiempo real**: Polling autom√°tico de resultados
- üîç **F√°cil de usar**: Interfaz intuitiva para hacer scrapping de URLs

## Arquitectura

```
web_client/
‚îú‚îÄ‚îÄ web_client.py   # Servidor HTTP y l√≥gica de conexi√≥n (Python)
‚îú‚îÄ‚îÄ index.html      # Interfaz de usuario
‚îú‚îÄ‚îÄ style.css       # Estilos CSS
‚îú‚îÄ‚îÄ script.js       # L√≥gica del frontend (JavaScript)
‚îî‚îÄ‚îÄ Dockerfile      # Contenedor Docker
```

### Componentes

1. **web_client.py**: 
   - Servidor HTTP usando `http.server.HTTPServer`
   - Mantiene conexi√≥n persistente con el Router usando `NodeConnection`
   - Reconexi√≥n autom√°tica si se pierde la conexi√≥n
   - API REST simple para:
     - `GET /`: P√°gina principal
     - `GET /api/status`: Estado de la conexi√≥n
     - `POST /api/scrape`: Enviar petici√≥n de scrapping
     - `GET /api/result/<task_id>`: Obtener resultado

2. **Frontend (HTML/CSS/JS)**:
   - Interfaz limpia y moderna
   - Actualizaci√≥n autom√°tica de estado cada 5 segundos
   - Polling de resultados cada 5 segundos
   - Visualizaci√≥n de enlaces encontrados

## Uso

### Con Docker (recomendado)

```bash
# Construir imagen
make build-web-client

# Ejecutar cliente web
make run-web-client

# Acceder en el navegador
http://localhost:8080
```

### Manual

```bash
cd web_client
python3 web_client.py
```

Variables de entorno:
- `ROUTER_HOST`: Hostname del router (default: `router`)
- `ROUTER_PORT`: Puerto del router (default: `7070`)
- `WEB_PORT`: Puerto del servidor web (default: `8080`)

## C√≥mo funciona

### 1. Conexi√≥n al Router

El cliente:
1. Resuelve IPs de routers usando DNS de Docker
2. Encuentra el router jefe enviando mensajes de identificaci√≥n
3. Establece conexi√≥n persistente usando `NodeConnection`
4. Monitorea la conexi√≥n cada 10 segundos

### 2. Reconexi√≥n Autom√°tica

Si la conexi√≥n se pierde:
1. El monitor detecta la desconexi√≥n
2. Fuerza re-descubrimiento de routers (busca nuevo jefe)
3. Establece nueva conexi√≥n autom√°ticamente
4. El usuario puede seguir usando la interfaz sin interrupciones

### 3. Peticiones de Scrapping

Flujo:
1. Usuario ingresa URL en la interfaz
2. JavaScript env√≠a POST a `/api/scrape`
3. Servidor env√≠a petici√≥n al Router con `NodeConnection`
4. JavaScript hace polling cada 5s a `/api/result/<task_id>`
5. Cuando llega el resultado, se muestra en la interfaz

### 4. Mensajes del Sistema

El cliente maneja:
- **IDENTIFICATION**: Identificaci√≥n con el router
- **REQUEST**: Env√≠o de peticiones de scrapping
- **RESULT**: Recepci√≥n de resultados

## Ventajas vs otros frameworks

### vs Streamlit
- ‚úÖ M√°s control sobre la UI
- ‚úÖ Mejor para APIs REST
- ‚úÖ M√°s liviano
- ‚ùå Menos componentes pre-hechos

### vs Flask
- ‚úÖ No requiere dependencias externas
- ‚úÖ M√°s simple para casos b√°sicos
- ‚ùå Menos features avanzados

### vs FastAPI
- ‚úÖ Sin dependencias
- ‚úÖ Python est√°ndar √∫nicamente
- ‚ùå Sin documentaci√≥n autom√°tica (OpenAPI)

## Ejemplo de uso

1. Abrir http://localhost:8080
2. Ingresar URL (ej: https://example.com)
3. Click en "üîç Scrapear"
4. Ver resultado en tiempo real cuando est√© listo

## Estado de la interfaz

La barra de estado muestra:
- **Estado**: Conectado/Desconectado al router
- **Router**: IP del router jefe actual
- **Pendientes**: Peticiones en proceso
- **Completadas**: Peticiones finalizadas

## Desarrollo

Para modificar la interfaz:
1. Editar `index.html`, `style.css` o `script.js`
2. Recargar p√°gina (no necesitas reiniciar servidor)

Para modificar la l√≥gica:
1. Editar `web_client.py`
2. Reiniciar servidor

## Troubleshooting

**Problema**: No se conecta al router
- Verificar que est√©s en la red `scrapper-network`
- Verificar que haya al menos un router corriendo
- Ver logs: `docker logs web-client`

**Problema**: Resultados no aparecen
- Verificar que haya scrappers disponibles
- El sistema puede tardar si todos los scrappers est√°n ocupados
- Timeout por defecto: 5 minutos

**Problema**: P√°gina no carga
- Verificar que el puerto 8080 no est√© en uso
- Revisar logs del contenedor
